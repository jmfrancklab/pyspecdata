{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# 2D ILT test\n\n2D regularization test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "try:\n    get_ipython().magic('load_ext pyspecdata.ipy')\n    in_notebook = True\nexcept:\n    from pyspecdata import *\n    in_notebook = False\nfrom pyspecdata import nnls_regularized\nfrom numpy import *\nimport time\nfl=figlist_var()\ninit_logging(level='debug')\n\n\n# got the following from here:\n# https://medium.com/pythonhive/python-decorator-to-measure-the-execution-time-of-methods-fa04cb6bb36d\n\n#l_line = ''\n#def timeit(method,n_times=5):\n#    def timed(*args, **kw):\n#        timing = zeros(n_times+1)\n#        timing[0] = time.time()\n#        for j in range(n_times):\n#            result = method(*args, **kw)\n#            timing[j+1] = time.time()\n#        time_diff = (timing[-1]-timing[0])/float(n_times)\n#        if 'log_time' in kw:\n#            name = kw.get('log_name', method.__name__.upper())\n#            kw['log_time'][name] = int(time_diff * 1000)\n#        else:\n#            print('%r  %2.2f ms (average of %d runs)' %(method.__name__, time_diff * 1000, n_times) + l_line)\n#        return result\n#    return timed\n#\n#\n## \n#\n#\n#R = r_[1.:100:500j] # distribution of T2 relaxation rates\n#peaks = [(80,4,1),(20,0.5,0.5),(30,0.5,0.25)]\n#calcd = False\n#for mu,sigma,A in peaks:\n#    if not calcd:\n#        P = A*exp(-(R-mu)**2/(2*sigma**2))\n#        calcd = True\n#    else:\n#        P += A*exp(-(R-mu)**2/(2*sigma**2))\n#P = nddata(P,'R')\n#print(\"your labels are\",P.dimlabels)\n#P.setaxis('R',R.ravel())\n#\n#\n## Vary R as we move along the rows\n#\n#fl.next('distribution function')\n#fl.plot(P)\n#\n#\n## \n#\n#\n#time_endpoint = 0.2\n#t = nddata(r_[1e-3:time_endpoint:2048j],'t') # column vectors give functions of time\n#R = P.fromaxis('R')\n#test_data = exp(-R*t).dot(P)\n#logger.debug(strm('when constructing test_data, shape of the data is',ndshape(test_data),\"len of axis_coords_error\",len(test_data.axis_coords_error)))\n#\n##test_data += random.normal(scale = 0.01,size=(2048,1))\n#test_data.add_noise(0.01)\n#fl.next('test data function')\n#fl.plot(test_data)\n#xlim(-time_endpoint/10,time_endpoint)\n#\n#\n## Do the basic NNLS fit\n#\n#\n#\n#logger.debug(strm('before nnls, shape of the data is',ndshape(test_data),\"len of axis_coords_error\",len(test_data.axis_coords_error)))\n#test_fit = test_data.C.nnls('t',R,lambda x,y: exp(-y*x))\n#fl.next('fit an exponential distribution',legend=True)\n#fl.plot(test_data, alpha=0.5, label='test signal')\n#K = test_fit.get_prop('nnls_kernel').C\n##note that order doesn't matter for the following dot (done by dimension name)\n#fl.plot(test_fit.C.dot(K), alpha=0.5, label='fit')\n#fl.next('what does the fit distribution look like?')\n#fl.plot(test_fit)\n#\n#\n## Now add regularization\n#\n#\n#def L_curve(l,r_norm,x_norm, show_l=None, s=1e-3,\n#        **kwargs):\n#    \"\"\"plot L-curve using\n#\n#    Parameters\n#    ==========\n#    l: double\n#        lambda values\n#    r_norm: double\n#        norm of the residual\n#    x_norm: double\n#        norm of solution vector\"\"\"\n#    print(l.shape, r_norm.shape, x_norm.shape)\n#    r_to_x = UnivariateSpline(log10(r_norm),log10(x_norm), s=s)\n#    r_fine = linspace(*tuple(log10(r_norm[r_[0,-1]]).tolist()+[1000]))\n#    plot(log10(r_norm),log10(x_norm),'o',**kwargs)\n#    a = gca().get_ylim()\n#    plot(r_fine,r_to_x(r_fine), alpha=0.3)\n#    gca().set_ylim(a)\n#    if show_l is not None:\n#        l_to_r = UnivariateSpline(l,log10(r_norm),s=1e-3)\n#        this_r = l_to_r(show_l)\n#        this_x = r_to_x(this_r)\n#        OLDplot(this_r,this_x,'ro')\n#        annotate('chosen $\\lambda=%3g$'%show_l, (this_r,this_x))\n#    for j,this_l in enumerate(l):\n#        annotate('%5g'%this_l, (log10(r_norm[j]),log10(x_norm[j])),\n#                 ha='left',va='bottom',rotation=45)\n#    ylabel('$\\log_{10}(x$ norm$)$')\n#    xlabel('$\\log_{10}($ residual $)$')\n#\n#\n## \n#\n#\n##l = sqrt(logspace(-8,4,10)) # I do this because it gives me a fairly even spacing of points\n###@timeit\n##def nonvec_lcurve(l):\n##    x_norm = empty_like(l)\n##    r_norm = empty_like(l)\n##    for j,this_l in enumerate(l):\n##        x = test_data.C.nnls('t',\n##                R,lambda x,y: exp(-y*x), l=this_l)\n##        r_norm[j] = x.get_prop('nnls_residual')\n##        x_norm[j] = linalg.norm(x.data)\n##    return x,x_norm,r_norm\n##x,x_norm,r_norm = nonvec_lcurve(l)\n###x_norm = map(linalg.norm,x) # to be fair, this calculation is done outside the timing, below\n##\n##\n### \n##\n##\n##fl.next('L-curve', legend=True);clf()\n##L_curve(l, r_norm, x_norm, markersize=10, alpha=0.5, label='manual loop')\n#\n#\n## ## Vectorized version of lambda curve\n#\n## \n#\n#\n#l = sqrt(logspace(-8,4,10)) # I do this because it gives me a fairly even spacing of points\n##@timeit\n#def vec_lcurve(l):\n#    return test_data.C.nnls('t',\n#            R,lambda x,y: exp(-y*x), l=l)\n#x = vec_lcurve(l)\n#\n#\n## \n#\n#\n#fl.next('L-curve')\n#logger.debug(strm(\"check dtype of residual:\",x.get_prop('nnls_residual').data.dtype))\n#L_curve(l, x.get_prop('nnls_residual').data, x.C.run(linalg.norm,'R').data,\n#        markersize=5, alpha=0.5, label='compiled loop')\n#\n#\n## ## 1.5D example -- very simplistic dataset\n## \n## (where the data is duplicated along the $\\Omega$ dimension)\n## \n## unlike for the numpy version, I skip straight to the\n## vectorized/parallel version.\n#\n#\n#l = sqrt(logspace(-8,4,10)) # I do this because it gives me a fairly even spacing of points\n#test_data_2d = test_data * nddata(r_[1,1,1],r'\\Omega')\n##@timeit\n#def multifreq_lcurve(l):\n#    return test_data_2d.C.nnls('t',\n#            R,lambda x,y: exp(-y*x), l=l)\n#x = multifreq_lcurve(l)\n#\n## \n#\n#fl.next('L-curve')\n#chosen_l = 0.025\n#L_curve(l, x.get_prop('nnls_residual')[r'\\Omega',0].data,\n#        x.C.run(linalg.norm,'R')[r'\\Omega',0].data, markersize=5, alpha=0.5,\n#        show_l=chosen_l,\n#        label='compiled loop')\n#\n## and show the final result\n## here, I omit the SVD (allows negative) result\n#\n#\n#fl.next(r'show result where $\\lambda$ set to knee')\n#test_data.nnls('t', R, lambda x,y: exp(-x*y), l=0.025)\n#fl.plot(test_data)\n#fl.plot(P)\n#\n#\n## ## 1.5D code -- a more complicated/realistic example\n## \n## First, generate a test distribution, where we assume we have two dimensions:\n## \n## *  A $t_2$ dimension, which is actually typically a frequency dimension\n## *  A $t_{indirect}$ dimension -- representing, *e.g.*, the delay of an inversion recovery experiment. \n#\n#\n#time_endpoint = 0.2\n#R = nddata(r_[1.:100:100j],'R') # distribution of T2 relaxation rates\n#t2 = nddata(r_[1e-3:time_endpoint:2048j],'t2') # column vectors give functions of time\n#peaks_2D = [(20,1,0.8,0.025,5e-3,1),\n#           (30,1,0.8,0.075,1e-2,1),\n#           (80,5,1,0.175,1e-2,1)]\n#data_dist = 0\n#for x_mu,x_sigma,x_amp,y_mu,y_sigma,y_amp in peaks_2D:\n#        data_dist += x_amp*y_amp*exp(-(R-x_mu)**2/2/x_sigma**2\n#                           -(t2-y_mu)**2/2/y_sigma**2)\n#fl.next('Test 1.5D true distribution')\n#fl.image(data_dist)\n#\n#\n## Convert to the time domain, where the $R$ dimension is replaced by a\n## $t_{indirect}$ dimension, and add noise\n#\n#\n#n_indirect = 128\n#t_indirect = nddata((r_[0:n_indirect]+1)/double(n_indirect),\n#        't_indirect')\n#kernel = exp(-t_indirect*R)\n#test_data_2d = kernel.C.dot(data_dist)\n#fl.next('Test 1.5D dataset')\n#test_data_2d.add_noise(0.1)\n#fl.image(test_data_2d)\n#\n#\n## Generate the L-curve\n#\n#l = sqrt(logspace(-8,4,10))\n##@timeit\n#def multifreq_lcurve(l):\n#    return test_data_2d.C.nnls('t_indirect',\n#            R,lambda x,y: exp(-y*x), l=l)\n#x = multifreq_lcurve(l)\n#\n#\n## \n#\n#\n#print(ndshape(test_data_2d))\n#print(ndshape(x))\n#\n#\n## \n#\n#\n#fl.next('L-curve')\n#heel_lambda = 0.215\n#L_curve(l, x.get_prop('nnls_residual').C.sum('t2').data,\n#        x.C.run(linalg.norm,'R').sum('t2').data, markersize=5, alpha=0.5,\n#        label='compiled loop',\n#        show_l=heel_lambda, s=1e-2)\n#\n#\n## Final result for 1.5D test data\n#\n#fl.next(r'show result where $\\lambda$ set to knee')\n#result = test_data_2d.C.nnls('t_indirect',R,\n#                    lambda x,y: exp(-y*x), l=heel_lambda)\n#fl.image(result)\n#\n#\n## ## Testing 2D BRD extension\n\ndef Gaussian_2D(x_axis,y_axis,mu_x,mu_y,sigma_x,sigma_y):\n    this_Gaussian = exp(-(x_axis-mu_x)**2/2/sigma_x**2\n                        -(y_axis-mu_y)**2/2/sigma_y**2)\n    return this_Gaussian\ndef Gaussian_2D_corr(theta,x_axis,y_axis,mu_x,mu_y,sigma_x,sigma_y):\n    diff_xy = cos(theta)*x_axis + sin(theta)*y_axis\n    sum_xy = -sin(theta)*x_axis + cos(theta)*y_axis\n    diff_mu = cos(theta)*mu_x + sin(theta)*mu_y\n    sum_mu = -sin(theta)*mu_x + cos(theta)*mu_y\n    this_Gaussian = exp(-(diff_xy-diff_mu)**2/2/sigma_x**2\n                       -(sum_xy-sum_mu)**2/2/sigma_y**2)\n    return this_Gaussian\n\nNx = 100\nNy = 50\nx_min = 3e-3; x_max = 3; y_min = 3e-3; y_max = 2;\nx_axis_log = nddata(linspace(log10(x_min),log10(x_max),Nx),r'log(T1)')\ny_axis_log = nddata(linspace(log10(y_min),log10(y_max),Ny),r'log(T2)')\n\nfl.next(r'True $T_{1}$,$T_{2}$')\ndist = Gaussian_2D(x_axis_log,y_axis_log,-1.6,-0.5,0.15,0.15)\ndist += Gaussian_2D_corr(-195*pi/180,x_axis_log,y_axis_log,-0.1,0.01,0.35,0.15)\ndist += Gaussian_2D_corr(-115*pi/180,x_axis_log,y_axis_log,-1.8,-1.5,0.09,0.15)\nfl.image(dist)\n\nN_tau1 = 30\nN_tau2 = 1000\ntau1_min = 5e-4; tau1_max = 4; tau2_min = 5e-4; tau2_max = 1.2\ntau1_axis = nddata(logspace(log10(tau1_min),log10(tau1_max),N_tau1),'tau1')\ntau2_axis = nddata(linspace(tau2_min,tau2_max,N_tau2),'tau2')\n\ns = dist*exp(-tau2_axis/(10**y_axis_log))*(1.-2*exp(-tau1_axis/(10**x_axis_log)))\ns.sum('log(T1)').sum('log(T2)')\ns /= amax(s.data)\ns.add_noise(0.03)\ns.reorder('tau1')\nfl.next('2D test data')\nfl.image(s)\n\nx_axis = nddata(10**x_axis_log.data.real,'T1')\ny_axis = nddata(10**y_axis_log.data.real,'T2')\n\nsolution = s.C.nnls(('tau1','tau2'),\n             (x_axis,y_axis),\n             (lambda x1,x2: 1.-2*exp(-x1/x2),\n             lambda y1,y2: exp(-y1/y2)),\n             l='BRD')\n\nfl.next('Solution')\nfl.image(solution)\n# \nif in_notebook:\n    print(\"in notebook, not calling show\")\nelse:\n    print(\"not in notebook, calling show\")\n    fl.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}